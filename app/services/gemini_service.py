# app/services/gemini_service.py

import json
import logging
import os
from typing import List

from fastapi import HTTPException, status
from google import genai
from google.api_core import exceptions as google_api_exceptions
from google.genai import types

from app.models.message import Message as MessageModel
from app.models.message import SenderType
from app.schemas.gemini import GeminiChatResponse

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)


class GeminiService:
    """Google Gemini AIì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤."""

    def __init__(self):
        self.client = None
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key:
            try:
                self.client = genai.Client(api_key=api_key)
                logger.info(
                    "âœ… GeminiService: Google Gen AI Client initialized successfully."
                )
            except Exception as e:
                logger.error(
                    f"âŒ GeminiService: Failed to initialize Google Gen AI Client: {e}",
                    exc_info=True,
                )
        else:
            logger.warning(
                "âš ï¸ GeminiService: GEMINI_API_KEY environment variable not found."
            )

    def is_available(self) -> bool:
        """ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ (í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€) í™•ì¸í•©ë‹ˆë‹¤."""
        return self.client is not None

    async def get_chat_response(
        self, system_prompt: str, history: List[MessageModel], user_message: str
    ) -> GeminiChatResponse:
        if not self.is_available():
            logger.error(
                "âŒ GeminiService: Cannot get chat response, service is not available."
            )
            raise ConnectionError(
                "AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            )

        try:
            # 1. ëŒ€í™” ê¸°ë¡ì„ genai.types.Content ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ì¬êµ¬ì„±
            reconstructed_history = []
            for msg in history:
                role = "user" if msg.sender_type == SenderType.USER else "model"
                reconstructed_history.append(
                    types.Content(
                        role=role, parts=[types.Part.from_text(text=msg.content)]
                    )
                )

            # 2. í† í° ê³„ì‚°ì„ ìœ„í•œ contents ë¦¬ìŠ¤íŠ¸ ìƒì„±
            contents_for_counting = (
                [
                    types.Content(
                        role="user", parts=[types.Part.from_text(text=system_prompt)]
                    ),
                    types.Content(
                        role="model",
                        parts=[
                            types.Part.from_text(
                                text="ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì§€ì‹œì— ë”°ë¥´ê² ìŠµë‹ˆë‹¤."
                            )
                        ],
                    ),
                ]
                + reconstructed_history
                + [
                    types.Content(
                        role="user", parts=[types.Part.from_text(text=user_message)]
                    )
                ]
            )

            token_count_response = await self.client.aio.models.count_tokens(
                model="models/gemini-1.5-flash-latest", contents=contents_for_counting
            )
            total_tokens = token_count_response.total_tokens

            # 3. JSON ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì¤€ë¹„
            response_schema = GeminiChatResponse.model_json_schema()
            if (
                "properties" in response_schema
                and "token_usage" in response_schema["properties"]
            ):
                del response_schema["properties"]["token_usage"]
                if (
                    "required" in response_schema
                    and "token_usage" in response_schema["required"]
                ):
                    response_schema["required"].remove("token_usage")

            # 4. â­ï¸ ìˆ˜ì •: generate_contentì— ì „ë‹¬í•  config ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
            generation_config = types.GenerateContentConfig(
                system_instruction=system_prompt,
                response_mime_type="application/json",
                response_schema=response_schema,
                temperature=0.7,
            )

            # 5. generate_contentì— ì „ë‹¬í•  contentsëŠ” ëŒ€í™” ê¸°ë¡ê³¼ ìƒˆ ë©”ì‹œì§€ë§Œ í¬í•¨
            contents_for_generation = reconstructed_history + [
                types.Content(
                    role="user", parts=[types.Part.from_text(text=user_message)]
                )
            ]

            # 6. â­ï¸ ìˆ˜ì •: 'config' íŒŒë¼ë¯¸í„°ì— ìœ„ì—ì„œ ìƒì„±í•œ ê°ì²´ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.
            response = await self.client.aio.models.generate_content(
                model="models/gemini-1.5-flash-latest",
                contents=contents_for_generation,
                config=generation_config,
            )

            # 7. ê²°ê³¼ íŒŒì‹± ë° ë°˜í™˜
            json_response = json.loads(response.text)
            json_response["token_usage"] = total_tokens

            logger.info(f"âœ… Gemini API call successful. Tokens used: {total_tokens}")
            return GeminiChatResponse(**json_response)

        except (
            google_api_exceptions.GoogleAPICallError,
            google_api_exceptions.RetryError,
        ) as e:
            logger.error(f"ğŸ”¥ Gemini API ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail=f"Google API ì˜¤ë¥˜: {e}",
            )
        except json.JSONDecodeError:
            logger.error(
                f"ğŸ”¥ JSON íŒŒì‹± ì˜¤ë¥˜: ëª¨ë¸ì´ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‘ë‹µ: {response.text}"
            )
            raise HTTPException(
                status_code=500, detail="ëª¨ë¸ë¡œë¶€í„° ìœ íš¨í•œ JSON ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            )
        except Exception as e:
            logger.error(f"ğŸ”¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise HTTPException(
                status_code=500, detail=f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
