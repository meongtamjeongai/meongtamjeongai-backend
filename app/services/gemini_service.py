# app/services/gemini_service.py

import json
import logging
import os
from typing import Any, Dict, List, Optional, Tuple

from fastapi import HTTPException, status
from google import genai
from google.api_core import exceptions as google_api_exceptions
from google.genai import types

from app.core.config import settings
from app.models.message import Message as MessageModel
from app.models.message import SenderType
from app.models.phishing_case import PhishingCase
from app.schemas.gemini import GeminiChatResponse

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)


class GeminiService:
    """Google Gemini AIì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤."""

    def __init__(self):
        self.client = None
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key:
            try:
                self.client = genai.Client(api_key=api_key)
                logger.info(
                    "âœ… GeminiService: Google Gen AI Client initialized successfully."
                )
            except Exception as e:
                logger.error(
                    f"âŒ GeminiService: Failed to initialize Google Gen AI Client: {e}",
                    exc_info=True,
                )
        else:
            logger.warning(
                "âš ï¸ GeminiService: GEMINI_API_KEY environment variable not found."
            )

    def is_available(self) -> bool:
        """ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ (í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€) í™•ì¸í•©ë‹ˆë‹¤."""
        return self.client is not None

    async def get_chat_response(
        self,
        system_prompt: str,
        history: List[MessageModel],
        user_message: str,
        image_base64: Optional[str] = None,
        phishing_case: Optional[PhishingCase] = None,
        starting_message: Optional[str] = None,
    ) -> Tuple[GeminiChatResponse, List[Dict[str, Any]]]:
        if not self.is_available():
            logger.error(
                "âŒ GeminiService: Cannot get chat response, service is not available."
            )
            raise ConnectionError(
                "AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            )

        try:
            # â­ï¸ í”¼ì‹± ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±
            final_system_prompt = system_prompt
            if phishing_case:
                # PhishingCase ê°ì²´ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…
                phishing_info = f"""
---
[ì˜¤ëŠ˜ì˜ í”¼ì‹± í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤]
ë„ˆëŠ” ì§€ê¸ˆë¶€í„° ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ í”¼ì‹± ê³µê²©ì„ ì‹œë„í•˜ëŠ” ì—­í• ì„ ë§¡ì•„ì•¼ í•´. ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ì•„ë˜ ì‹œë‚˜ë¦¬ì˜¤ì˜ ëª©ì ì„ ë‹¬ì„±í•´ì¤˜.

- ìœ í˜•: {phishing_case.category.description if phishing_case.category else "ì¼ë°˜ ì‚¬ê¸°"}
- ì œëª©: {phishing_case.title}
- í•µì‹¬ ë‚´ìš©: {phishing_case.content}
---
"""
                final_system_prompt += phishing_info

            # 1. ëŒ€í™” ê¸°ë¡ì„ genai.types.Content ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ì¬êµ¬ì„±
            reconstructed_history = []
            for msg in history:
                role = "user" if msg.sender_type == SenderType.USER else "model"
                reconstructed_history.append(
                    types.Content(
                        role=role, parts=[types.Part.from_text(text=msg.content)]
                    )
                )

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” í•­ìƒ ê¸°ë³¸ìœ¼ë¡œ í¬í•¨
            contents_for_generation = []

            # âœ¨ ì‹œì‘ ë©”ì‹œì§€ê°€ ìˆê³ , ì‹¤ì œ DB ëŒ€í™” ê¸°ë¡ì´ ë¹„ì–´ìˆì„ ë•Œë§Œ ì£¼ì…
            if starting_message and not history:
                # AIì˜ ì²« ë°œì–¸ìœ¼ë¡œ ì·¨ê¸‰ (role='model')
                contents_for_generation.append(
                    types.Content(
                        role="model",
                        parts=[types.Part.from_text(text=starting_message)],
                    )
                )

            # ì‹¤ì œ ëŒ€í™” ê¸°ë¡ê³¼ í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì¶”ê°€
            contents_for_generation.extend(reconstructed_history)
            contents_for_generation.append(
                types.Content(
                    role="user", parts=[types.Part.from_text(text=user_message)]
                )
            )

            # í† í° ê³„ì‚°ì„ ìœ„í•œ contentsëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ìƒì„±ìš© contentsë¡œ êµ¬ì„±
            contents_for_counting = [
                types.Content(
                    role="user", parts=[types.Part.from_text(text=final_system_prompt)]
                ),
                types.Content(
                    role="model",
                    parts=[
                        types.Part.from_text(
                            text="ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì§€ì‹œì— ë”°ë¥´ê² ìŠµë‹ˆë‹¤."
                        )
                    ],
                ),
            ] + contents_for_generation

            token_count_response = await self.client.aio.models.count_tokens(
                model=settings.GEMINI_MODEL_NAME,
                contents=contents_for_counting,
            )
            total_tokens = token_count_response.total_tokens

            # 3. JSON ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì¤€ë¹„
            response_schema = GeminiChatResponse.model_json_schema()
            if (
                "properties" in response_schema
                and "token_usage" in response_schema["properties"]
            ):
                del response_schema["properties"]["token_usage"]
                if (
                    "required" in response_schema
                    and "token_usage" in response_schema["required"]
                ):
                    response_schema["required"].remove("token_usage")

            # 4. â­ï¸ [ë³€ê²½] generate_contentì— ì „ë‹¬í•  config ê°ì²´ë¥¼ ìƒì„±
            generation_config = types.GenerateContentConfig(
                system_instruction=final_system_prompt,  # â­ï¸ ìˆ˜ì •ëœ ìµœì¢… í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                response_mime_type="application/json",
                response_schema=response_schema,
                temperature=0.7,
            )

            # 5. generate_contentì— ì „ë‹¬í•  contentsëŠ” ëŒ€í™” ê¸°ë¡ê³¼ ìƒˆ ë©”ì‹œì§€ë§Œ í¬í•¨
            contents_for_generation = reconstructed_history + [
                types.Content(
                    role="user", parts=[types.Part.from_text(text=user_message)]
                )
            ]

            # 6. â­ï¸ [ë³€ê²½] 'config' íŒŒë¼ë¯¸í„°ì— ìœ„ì—ì„œ ìƒì„±í•œ ê°ì²´ë¥¼ ì „ë‹¬
            response = await self.client.aio.models.generate_content(
                model=settings.GEMINI_MODEL_NAME,
                contents=contents_for_generation,
                config=generation_config,
            )

            # 7. ê²°ê³¼ íŒŒì‹± ë° ë°˜í™˜
            json_response = json.loads(response.text)
            json_response["token_usage"] = total_tokens

            logger.info(f"âœ… Gemini API call successful. Tokens used: {total_tokens}")

            debug_contents = [
                {
                    "role": content.role,
                    "parts": [part.text for part in content.parts],
                }
                for content in contents_for_counting
            ]

            logger.info("=" * 50)
            logger.info(
                f"ğŸš€ ìµœì¢… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (To Gemini API for Conv ID: {history[0].conversation_id if history else 'N/A'})"
            )
            logger.info(final_system_prompt)
            logger.info("=" * 50)

            return GeminiChatResponse(**json_response), debug_contents

        except (
            google_api_exceptions.GoogleAPICallError,
            google_api_exceptions.RetryError,
        ) as e:
            logger.error(f"ğŸ”¥ Gemini API ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail=f"Google API ì˜¤ë¥˜: {e}",
            )
        except json.JSONDecodeError:
            logger.error(
                f"ğŸ”¥ JSON íŒŒì‹± ì˜¤ë¥˜: ëª¨ë¸ì´ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‘ë‹µ: {response.text}"
            )
            raise HTTPException(
                status_code=500, detail="ëª¨ë¸ë¡œë¶€í„° ìœ íš¨í•œ JSON ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            )
        except Exception as e:
            logger.error(f"ğŸ”¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise HTTPException(
                status_code=500, detail=f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
