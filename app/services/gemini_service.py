# app/services/gemini_service.py

import base64
import json
import logging
import os
from io import BytesIO
from typing import Any, Dict, List, Optional, Tuple

from fastapi import HTTPException, status
from google import genai
from google.api_core import exceptions as google_api_exceptions
from google.genai import types
from PIL import Image

from app.core.config import settings
from app.models.message import Message as MessageModel
from app.models.message import SenderType
from app.models.phishing_case import PhishingCase
from app.schemas.gemini import GeminiChatResponse

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)


class GeminiService:
    """Google Gemini AIì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” ì„œë¹„ìŠ¤."""

    def __init__(self):
        self.client = None
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key:
            try:
                # ğŸ’¡ [ìˆ˜ì •] genai.configure()ë¥¼ ì‚¬ìš©í•˜ì—¬ API í‚¤ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì´ ê¶Œì¥ ë°©ì‹ì…ë‹ˆë‹¤.
                genai.configure(api_key=api_key)
                # ğŸ’¡ [ìˆ˜ì •] GenerativeModelì„ ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì§ê´€ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                self.model = genai.GenerativeModel(
                    model_name=settings.GEMINI_MODEL_NAME
                )
                logger.info(
                    "âœ… GeminiService: Google Gen AI Client initialized successfully."
                )
            except Exception as e:
                logger.error(
                    f"âŒ GeminiService: Failed to initialize Google Gen AI Client: {e}",
                    exc_info=True,
                )
                self.model = None
        else:
            logger.warning(
                "âš ï¸ GeminiService: GEMINI_API_KEY environment variable not found."
            )
            self.model = None

    def is_available(self) -> bool:
        """ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ (í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€) í™•ì¸í•©ë‹ˆë‹¤."""
        return self.model is not None

    async def get_chat_response(
        self,
        system_prompt: str,
        history: List[MessageModel],
        user_message: str,
        image_base64: Optional[str] = None,
        phishing_case: Optional[PhishingCase] = None,
        starting_message: Optional[str] = None,
    ) -> Tuple[GeminiChatResponse, List[Dict[str, Any]]]:
        if not self.is_available():
            logger.error(
                "âŒ GeminiService: Cannot get chat response, service is not available."
            )
            raise ConnectionError(
                "AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            )

        try:
            final_system_prompt = system_prompt
            if phishing_case:
                phishing_info = f"""
---
[ì˜¤ëŠ˜ì˜ í”¼ì‹± í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤]
ë„ˆëŠ” ì§€ê¸ˆë¶€í„° ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ í”¼ì‹± ê³µê²©ì„ ì‹œë„í•˜ëŠ” ì—­í• ì„ ë§¡ì•„ì•¼ í•´. ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ í†µí•´ ì•„ë˜ ì‹œë‚˜ë¦¬ì˜¤ì˜ ëª©ì ì„ ë‹¬ì„±í•´ì¤˜.

- ìœ í˜•: {phishing_case.category.description if phishing_case.category else "ì¼ë°˜ ì‚¬ê¸°"}
- ì œëª©: {phishing_case.title}
- í•µì‹¬ ë‚´ìš©: {phishing_case.content}
---
"""
                final_system_prompt += phishing_info

            reconstructed_history = []
            for msg in history:
                role = "user" if msg.sender_type == SenderType.USER else "model"
                msg_parts = [types.Part.from_text(text=msg.content)]
                reconstructed_history.append(types.Content(role=role, parts=msg_parts))

            contents_for_generation = []
            if starting_message and not history:
                contents_for_generation.append(
                    types.Content(
                        role="model",
                        parts=[types.Part.from_text(text=starting_message)],
                    )
                )

            contents_for_generation.extend(reconstructed_history)

            user_parts = [types.Part.from_text(text=user_message)]
            if image_base64:
                try:
                    image_data = base64.b64decode(image_base64)
                    img = Image.open(BytesIO(image_data))
                    mime_type = Image.MIME.get(img.format)
                    if not mime_type:
                        raise ValueError("Could not determine image MIME type.")

                    user_parts.append(
                        types.Part(
                            inline_data=types.Blob(mime_type=mime_type, data=image_data)
                        )
                    )
                    logger.info(
                        f"âœ… ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ Gemini ìš”ì²­ì— í¬í•¨í–ˆìŠµë‹ˆë‹¤. (MIME: {mime_type})"
                    )
                except Exception as e:
                    logger.error(f"ğŸ”¥ Base64 ì´ë¯¸ì§€ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    pass

            contents_for_generation.append(types.Content(role="user", parts=user_parts))

            contents_for_counting = [
                types.Content(
                    role="user", parts=[types.Part.from_text(text=final_system_prompt)]
                ),
                types.Content(
                    role="model",
                    parts=[
                        types.Part.from_text(
                            text="ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì§€ì‹œì— ë”°ë¥´ê² ìŠµë‹ˆë‹¤."
                        )
                    ],
                ),
            ] + contents_for_generation

            token_count_response = await genai.caching.get_async_client().count_tokens(
                model=self.model.model_name,
                contents=contents_for_counting,
            )
            total_tokens = token_count_response.total_tokens

            response_schema = GeminiChatResponse.model_json_schema()
            if (
                "properties" in response_schema
                and "token_usage" in response_schema["properties"]
            ):
                del response_schema["properties"]["token_usage"]
                if (
                    "required" in response_schema
                    and "token_usage" in response_schema["required"]
                ):
                    response_schema["required"].remove("token_usage")

            generation_config = types.GenerationConfig(
                response_mime_type="application/json",
                response_schema=response_schema,
                temperature=0.7,
            )

            # --- âœ… [ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€] ---
            logger.info("--- ğŸš€ ìµœì¢… Gemini ìš”ì²­ Contents ---")
            for content in contents_for_generation:
                part_details = []
                for part in content.parts:
                    if hasattr(part, "text"):
                        part_details.append(f"Text(len={len(part.text)})")
                    elif hasattr(part, "inline_data"):
                        part_details.append(
                            f"Image(mime={part.inline_data.mime_type}, len={len(part.inline_data.data)})"
                        )
                logger.info(f"Role: {content.role}, Parts: {part_details}")
            logger.info("------------------------------------")

            response = await self.model.generate_content_async(
                contents=contents_for_generation,
                generation_config=generation_config,
                system_instruction=final_system_prompt,
            )

            json_response = json.loads(response.text)
            json_response["token_usage"] = total_tokens

            logger.info(f"âœ… Gemini API call successful. Tokens used: {total_tokens}")

            debug_contents = [
                {
                    "role": content.role,
                    "parts": [part.text for part in content.parts],
                }
                for content in contents_for_counting
            ]

            logger.info("=" * 50)
            logger.info(
                f"ğŸš€ ìµœì¢… ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (To Gemini API for Conv ID: {history[0].conversation_id if history else 'N/A'})"
            )
            logger.info(final_system_prompt)
            logger.info("=" * 50)

            return GeminiChatResponse(**json_response), debug_contents

        except (
            google_api_exceptions.GoogleAPICallError,
            google_api_exceptions.RetryError,
        ) as e:
            logger.error(f"ğŸ”¥ Gemini API ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail=f"Google API ì˜¤ë¥˜: {e}",
            )
        except json.JSONDecodeError:
            logger.error(
                f"ğŸ”¥ JSON íŒŒì‹± ì˜¤ë¥˜: ëª¨ë¸ì´ ìœ íš¨í•œ JSONì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‘ë‹µ: {response.text}"
            )
            raise HTTPException(
                status_code=500, detail="ëª¨ë¸ë¡œë¶€í„° ìœ íš¨í•œ JSON ì‘ë‹µì„ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            )
        except Exception as e:
            logger.error(f"ğŸ”¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise HTTPException(
                status_code=500, detail=f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
